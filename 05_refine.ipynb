{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: refine.html\n",
    "title: refine\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "import math\n",
    "from collections import defaultdict, OrderedDict\n",
    "from dataclasses import dataclass\n",
    "from joblib import Parallel, delayed\n",
    "from operator import sub\n",
    "from statistics import mean\n",
    "from LAFITE.utils import loc_distance, Vividict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@ dataclass\n",
    "class AttributeCollection:\n",
    "\tstart: int\n",
    "\tend: int\n",
    "\tcount: float\n",
    "\tpolya_count: int = None\n",
    "\tfsm: bool = False\n",
    "\tpolyaed: bool = False\n",
    "\tas_site: list = None\n",
    "\tapa_site: list = None\n",
    "\tname: str = None\n",
    "\treference_id: list =None\n",
    "\trss_dis: int = math.inf\n",
    "\tread_tag: str = None\n",
    "\tprocessed: bool = False\n",
    "\tchrand_ID: int = None\n",
    "\tloci_ID: int = None\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "class SingleExonReadRefine:\n",
    "\tdef __init__(self, chrom, strand, chrand_collected_single_exon_read, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_three_prime_exon, min_single_exon_coverage, min_single_exon_len, rs_tolerance = 24, coverage_cliff = 0):\n",
    "\t\tself.chrom = chrom\n",
    "\t\tself.strand = strand\n",
    "\t\tself.chrand_collected_single_exon_read = chrand_collected_single_exon_read\n",
    "\t\tself.chrand_ref_single_exon_trans = chrand_ref_single_exon_trans\n",
    "\t\tself.chrand_ref_mutple_exon_trans = chrand_ref_mutple_exon_trans\n",
    "\t\tself.chrand_three_prime_exon = chrand_three_prime_exon\n",
    "\t\tself.min_single_exon_coverage = min_single_exon_coverage\n",
    "\t\tself.min_single_exon_len = min_single_exon_len\n",
    "\t\tself.rs_tolerance = rs_tolerance\n",
    "\t\tself.coverage_cliff = coverage_cliff\n",
    "\n",
    "\tdef single_exon_refine(self, subread, position, coverage, refined_single_exon_read, i):\n",
    "\t\tif subread[1]-subread[0] >= self.min_single_exon_len:\n",
    "\t\t\tsubread_attribute = AttributeCollection(position[subread[0]], position[subread[1]], mean(coverage[subread[0]:subread[1]]))\n",
    "\t\t\tif self.chrand_ref_single_exon_trans:\n",
    "\t\t\t\toverlap_ref = tuple(self.chrand_ref_single_exon_trans.find((position[subread[0]],position[subread[1]])))\n",
    "\t\t\t\tif overlap_ref:\n",
    "\t\t\t\t\tfor ref_exon in overlap_ref:\n",
    "\t\t\t\t\t\toverlap = list(set(range(position[subread[0]], position[subread[1]]+1)).intersection(range(ref_exon[0],ref_exon[1]+1)))\n",
    "\t\t\t\t\t\toverlap.sort()\n",
    "\t\t\t\t\t\tif (overlap[-1] - overlap[0] + 1)/(ref_exon[1] - ref_exon[0] + 1) >= 0.5:\n",
    "\t\t\t\t\t\t\tsubread_attribute.processed = True\n",
    "\t\t\t\t\t\t\tsubread_attribute.read_tag = 'Keep_ref'\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\tif not subread_attribute.processed and self.chrand_three_prime_exon:\n",
    "\t\t\t\toverlap_ref = tuple(self.chrand_three_prime_exon.find((position[subread[0]],position[subread[1]])))\n",
    "\t\t\t\tif overlap_ref:\n",
    "\t\t\t\t\tfor ref_exon in overlap_ref:\n",
    "\t\t\t\t\t\tif (self.strand == '+' and position[subread[0]] > ref_exon[0] - self.rs_tolerance) or (self.strand == '-' and position[subread[1]] < ref_exon[1] + self.rs_tolerance):\n",
    "\t\t\t\t\t\t\tsubread_attribute.processed = True\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\tif not subread_attribute.processed:\n",
    "\t\t\t\tif subread_attribute.count >= self.min_single_exon_coverage:\n",
    "\t\t\t\t\tsubread_attribute.processed = True\n",
    "\t\t\t\t\tsubread_attribute.read_tag = 'Keep_coverage'\n",
    "\t\t\tif subread_attribute.read_tag:\n",
    "\t\t\t\trefined_single_exon_read[(position[subread[0]], position[subread[1]])] = subread_attribute\n",
    "\t\tsubread = [i+1,i+1]\n",
    "\t\treturn subread, refined_single_exon_read\n",
    "\n",
    "\tdef refine(self):\n",
    "\t\trefined_single_exon_read = defaultdict(dict)\n",
    "\t\tchrand_collected_single_exon_read = dict(OrderedDict(sorted(self.chrand_collected_single_exon_read.items())))\n",
    "\t\tposition = list(chrand_collected_single_exon_read.keys())\n",
    "\t\tcoverage = list(chrand_collected_single_exon_read.values())\n",
    "\t\tsubread = [0,0]\n",
    "\t\tif not self.chrand_ref_mutple_exon_trans:\n",
    "\t\t\tself.coverage_cliff = 0.9\n",
    "\t\tfor i in range(len(position)-1):\n",
    "\t\t\tif position[i+1] == position[i]+1 and ((self.strand == '+' and coverage[i+1]/coverage[i]>= self.coverage_cliff) or (self.strand == '-' and coverage[i]/coverage[i+1]>= self.coverage_cliff)):\n",
    "\t\t\t\tsubread[1] = i+1\n",
    "\t\t\t\tif i == len(position) - 2:\n",
    "\t\t\t\t\tsubread, refined_single_exon_read = self.single_exon_refine(subread, position, coverage, refined_single_exon_read, i)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsubread, refined_single_exon_read = self.single_exon_refine(subread, position, coverage, refined_single_exon_read, i)\n",
    "\t\treturn self.chrom, self.strand, refined_single_exon_read\n",
    "\t\t\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "class MultiExonReadRefine():\n",
    "\tdef __init__(self, chrom, strand, chrand_processed_collected_multi_exon_read, chrand_ref_mutple_exon_trans, chrand_tss_dict, tss_cutoff, tes_cutoff, min_novel_trans_count, relative_fl_coverage=5, rs_tolerance=24, re_tolerance=50):\n",
    "\t\tself.chrom = chrom\n",
    "\t\tself.strand = strand\n",
    "\t\tself.chrand_processed_collected_multi_exon_read = chrand_processed_collected_multi_exon_read\n",
    "\t\tself.chrand_ref_mutple_exon_trans = chrand_ref_mutple_exon_trans\n",
    "\t\tself.chrand_tss_dict = chrand_tss_dict\n",
    "\t\tself.tss_cutoff = tss_cutoff\n",
    "\t\tself.tes_cutoff = tes_cutoff\n",
    "\t\tself.rs_tolerance = rs_tolerance\n",
    "\t\tself.re_tolerance = re_tolerance\n",
    "\t\tself.min_novel_trans_count = min_novel_trans_count\n",
    "\t\tself.relative_fl_coverage = relative_fl_coverage\n",
    "\n",
    "\tdef trucated_reads_filtering(self, start, end, corrected_read_splicing, trans_structure_pool, refined_multi_exon_read, total_count):\n",
    "\t\tfor ref_iso_splicing in trans_structure_pool:\n",
    "\t\t\ttmp_tag = None\n",
    "\t\t\tif len(ref_iso_splicing) > len(corrected_read_splicing):\n",
    "\t\t\t\tif set(corrected_read_splicing).issubset(set(ref_iso_splicing)):\n",
    "\t\t\t\t\tidx_start = ref_iso_splicing.index(corrected_read_splicing[0])\n",
    "\t\t\t\t\tidx_end = ref_iso_splicing.index(corrected_read_splicing[-1])\n",
    "\t\t\t\t\tif corrected_read_splicing == ref_iso_splicing[idx_start:idx_end+1]:\n",
    "\t\t\t\t\t\tif self.strand == '+' and idx_start > 0:\n",
    "\t\t\t\t\t\t\tif idx_end == len(ref_iso_splicing) -1:\n",
    "\t\t\t\t\t\t\t\tif start >= ref_iso_splicing[idx_start-1] - self.rs_tolerance:\n",
    "\t\t\t\t\t\t\t\t\ttmp_tag = 'Disqualify_Trucated_ISM'\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tif start >= ref_iso_splicing[idx_start-1] - self.rs_tolerance and end <= ref_iso_splicing[idx_end+1] + self.re_tolerance:\n",
    "\t\t\t\t\t\t\t\t\ttmp_tag = 'Disqualify_Trucated_ISM'\n",
    "\n",
    "\t\t\t\t\t\telif self.strand == '-' and idx_end < len(ref_iso_splicing)-1:\n",
    "\t\t\t\t\t\t\tif idx_start == 0:\n",
    "\t\t\t\t\t\t\t\tif start <= ref_iso_splicing[idx_end+1] + self.rs_tolerance:\n",
    "\t\t\t\t\t\t\t\t\ttmp_tag = 'Disqualify_Trucated_ISM'\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tif start <= ref_iso_splicing[idx_end+1] + self.rs_tolerance and end >= ref_iso_splicing[idx_start-1] - self.rs_tolerance:\n",
    "\t\t\t\t\t\t\t\t\ttmp_tag = 'Disqualify_Trucated_ISM'\n",
    "\t\t\t\t\tif tmp_tag:\n",
    "\t\t\t\t\t\tif ref_iso_splicing in refined_multi_exon_read:\n",
    "\t\t\t\t\t\t\tif total_count/refined_multi_exon_read[ref_iso_splicing].count >= self.relative_fl_coverage:\n",
    "\t\t\t\t\t\t\t\ttmp_tag = None\n",
    "\t\t\t\t\tif tmp_tag:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\treturn tmp_tag\n",
    "\n",
    "\tdef ISM_NIC_sorting(self, corrected_read_splicing, trans_structure_pool, rss_dis, total_count, start_pos = [], relative_intact = [], tmp_tag = None):\n",
    "\t\tfor ref_iso_splicing in trans_structure_pool:\n",
    "\t\t\tif len(ref_iso_splicing) > len(corrected_read_splicing):\n",
    "\t\t\t\tif set(corrected_read_splicing).issubset(set(ref_iso_splicing)):\n",
    "\t\t\t\t\tidx_start = ref_iso_splicing.index(corrected_read_splicing[0])\n",
    "\t\t\t\t\tidx_end = ref_iso_splicing.index(corrected_read_splicing[-1])\n",
    "\t\t\t\t\tif (self.strand == '+' and idx_start == 0) or (self.strand == '-' and idx_end == len(ref_iso_splicing)-1):\n",
    "\t\t\t\t\t\tstart_pos.append(1)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tstart_pos.append(0)\n",
    "\t\t\t\t\tref_exon_num = (len(ref_iso_splicing)+2)/2 \n",
    "\t\t\t\t\tif self.strand == '+':\n",
    "\t\t\t\t\t\trelative_intact.append((ref_exon_num - idx_start/2)/ref_exon_num)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\trelative_intact.append(((idx_end+3)/2)/ref_exon_num)\n",
    "\t\tif start_pos:\n",
    "\t\t\tif all(start_pos) or rss_dis < self.tss_cutoff:\n",
    "\t\t\t\ttmp_tag = 'Subset'\n",
    "\t\t\telif total_count >= self.min_novel_trans_count and mean(relative_intact) > 0.5:\n",
    "\t\t\t\ttmp_tag = 'Subset_coverage'\n",
    "\t\t\telse:\n",
    "\t\t\t\ttmp_tag = 'Disqualify_ISM_NIC'\n",
    "\t\t\n",
    "\t\treturn tmp_tag\n",
    "\n",
    "\t\n",
    "\tdef closest_ref_trans (self, corrected_read_splicing, trans_structure_pool):\n",
    "\t\t\"\"\" return the closest reference transcripts for the input read\n",
    "\t\t\"\"\"\n",
    "\t\tinter_SJ = ()\n",
    "\t\tcmp_trans = ()\n",
    "\t\tfor ref_iso_splicing in trans_structure_pool:\n",
    "\t\t\tif self.strand == '-':\n",
    "\t\t\t\tref_iso_splicing = tuple(reversed(ref_iso_splicing))\n",
    "\t\t\t\tcorrected_read_splicing = tuple(reversed(corrected_read_splicing))\n",
    "\n",
    "\t\t\ttmp_inter = list(set(ref_iso_splicing).intersection(set(corrected_read_splicing)))\n",
    "\t\t\ttmp_inter.sort(reverse=True)\n",
    "\t\t\tif len(tmp_inter) > len(inter_SJ):\n",
    "\t\t\t\tinter_SJ, cmp_trans = tmp_inter, ref_iso_splicing\n",
    "\t\t\telif len(tmp_inter) == len(inter_SJ) and len(tmp_inter) > 0:\n",
    "\t\t\t\tindex1 = [i for i, val in enumerate(cmp_trans) if val in inter_SJ] \n",
    "\t\t\t\tindex2 = [i for i, val in enumerate(ref_iso_splicing) if val in tmp_inter] \n",
    "\t\t\t\tindex_sub = list(map(sub, index1, index2))\n",
    "\t\t\t\tif any(index_sub):\n",
    "\t\t\t\t\tif index_sub[next((i for i, x in enumerate(index_sub) if x!=0), None)] > 0:\n",
    "\t\t\t\t\t\tinter_SJ = tmp_inter\n",
    "\t\t\t\t\t\tcmp_trans = ref_iso_splicing\n",
    "\t\t\t\telif len(ref_iso_splicing) < len(cmp_trans):\n",
    "\t\t\t\t\tinter_SJ = tmp_inter\n",
    "\t\t\t\t\tcmp_trans = ref_iso_splicing\n",
    "\t\t\n",
    "\t\tif self.strand == '-':\n",
    "\t\t\tcmp_trans = tuple(reversed(cmp_trans))\n",
    "\n",
    "\t\treturn len(inter_SJ), cmp_trans\n",
    "\t\n",
    "\tdef secondary_refine(self, corrected_read_splicing, read_attribute, refined_multi_exon_read, loci_idx):\n",
    "\t\tif 'Disqualify' not in read_attribute.read_tag:\n",
    "\t\t\tif read_attribute.read_tag != 'Reference':\n",
    "\t\t\t\tfor ref_iso_splicing in refined_multi_exon_read:\n",
    "\t\t\t\t\tif set(corrected_read_splicing).issubset(set(ref_iso_splicing)):\n",
    "\t\t\t\t\t\tidx_start = ref_iso_splicing.index(corrected_read_splicing[0])\n",
    "\t\t\t\t\t\tidx_end = ref_iso_splicing.index(corrected_read_splicing[-1])\n",
    "\t\t\t\t\t\tif corrected_read_splicing == ref_iso_splicing[idx_start:idx_end+1]:\n",
    "\t\t\t\t\t\t\tif (self.strand == '+' and idx_end == len(ref_iso_splicing) -1) or (self.strand == '-' and idx_start == 0):\n",
    "\t\t\t\t\t\t\t\tif (self.strand == \"+\" and read_attribute.start >= ref_iso_splicing[idx_start-1] - self.rs_tolerance) or (self.strand == \"-\" and read_attribute.start <= ref_iso_splicing[idx_end+1] + self.rs_tolerance):\n",
    "\t\t\t\t\t\t\t\t\tif read_attribute.count/refined_multi_exon_read[ref_iso_splicing].count < self.relative_fl_coverage:\n",
    "\t\t\t\t\t\t\t\t\t\tread_attribute.read_tag = 'Disqualify_merged'\n",
    "\t\t\t\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\tif 'Disqualify' not in read_attribute.read_tag:\n",
    "\t\t\tlen_inter_SJ, cmp_trans = self.closest_ref_trans(corrected_read_splicing, refined_multi_exon_read)\n",
    "\t\t\tif len_inter_SJ > 0:\n",
    "\t\t\t\tread_attribute.chrand_ID = refined_multi_exon_read[cmp_trans].chrand_ID\n",
    "\t\t\telse:\n",
    "\t\t\t\tloci_idx += 1\n",
    "\t\t\t\tread_attribute.chrand_ID = loci_idx\n",
    "\n",
    "\t\t\trefined_multi_exon_read[corrected_read_splicing] = read_attribute\n",
    "\n",
    "\t\treturn refined_multi_exon_read, read_attribute, loci_idx\n",
    "\n",
    "\n",
    "\tdef main_refine(self, loci_idx = 0):\n",
    "\t\trefined_multi_exon_read = defaultdict(dict)\n",
    "\t\trefine_log = defaultdict(dict)\n",
    "\t\tfor corrected_read_splicing, read_info in self.chrand_processed_collected_multi_exon_read.items():\n",
    "\t\t\tread_attribute = AttributeCollection(*read_info)\n",
    "\t\t\t# print(read_info)\n",
    "\t\t\ttrans_structure_pool = self.chrand_ref_mutple_exon_trans\n",
    "\n",
    "\t\t\t# calculate the distance between TSS of the collapsed read and nearest reference TSS\n",
    "\t\t\tread_attribute.rss_dis, _ = loc_distance(self.chrand_tss_dict, read_attribute.start)\n",
    "\n",
    "\t\t\t# check full splicing match reads whose rss and exactly matched reference transcripts \n",
    "\t\t\tif read_attribute.fsm:\n",
    "\t\t\t\tif any(abs(x - trans_structure_pool[corrected_read_splicing][0]) <= self.tss_cutoff for x in read_attribute.as_site):\n",
    "\t\t\t\t\tif read_attribute.polyaed:\n",
    "\t\t\t\t\t\tread_attribute.read_tag = 'Reference'\n",
    "\t\t\t\t\t\tread_attribute.processed = True\n",
    "\t\t\t\t\telif any(abs(x - trans_structure_pool[corrected_read_splicing][1]) <= self.tes_cutoff for x in read_attribute.apa_site):\n",
    "\t\t\t\t\t\tread_attribute.read_tag = 'Reference'\n",
    "\t\t\t\t\t\tread_attribute.processed = True\n",
    "\n",
    "\t\t\tif not read_attribute.processed:\n",
    "\t\t\t\t# check if read is trucated\n",
    "\t\t\t\tif trans_structure_pool:\n",
    "\t\t\t\t\tread_tag = self.trucated_reads_filtering(read_attribute.start, read_attribute.end, corrected_read_splicing, trans_structure_pool, refined_multi_exon_read, read_attribute.count)\n",
    "\t\t\t\t\tif read_tag:\n",
    "\t\t\t\t\t\tread_attribute.read_tag = read_tag\n",
    "\t\t\t\t\t\tread_attribute.processed = True\n",
    "\n",
    "\t\t\t\tif not read_attribute.processed and read_attribute.fsm:\n",
    "\t\t\t\t\tread_attribute.read_tag = 'Reference'\n",
    "\t\t\t\t\tread_attribute.processed = True\n",
    "\t\t\t\t\n",
    "\t\t\t\tif not read_attribute.processed and not read_attribute.polyaed:\n",
    "\t\t\t\t\tread_attribute.read_tag = 'Disqualify_No_ployA'\n",
    "\t\t\t\t\tread_attribute.processed = True\n",
    "\t\t\t\t\t\n",
    "\t\t\t\telif not read_attribute.processed:\n",
    "\t\t\t\t\tif trans_structure_pool:\n",
    "\t\t\t\t\t\tread_tag = self.ISM_NIC_sorting(corrected_read_splicing, trans_structure_pool, read_attribute.rss_dis, read_attribute.count, start_pos = [], tmp_tag = None)\n",
    "\t\t\t\t\t\tif read_tag:\n",
    "\t\t\t\t\t\t\tread_attribute.read_tag = read_tag\n",
    "\t\t\t\t\t\t\tread_attribute.processed = True\n",
    "\n",
    "\t\t\t\t\tif not read_attribute.processed:\n",
    "\t\t\t\t\t\tlen_inter_SJ, cmp_trans = self.closest_ref_trans(corrected_read_splicing, trans_structure_pool)\n",
    "\t\t\t\t\t\tread_attribute.processed = True\n",
    "\t\t\t\t\t\tif len_inter_SJ > 0:\n",
    "\t\t\t\t\t\t\tif (cmp_trans[0] == corrected_read_splicing[0]) or set(cmp_trans).issubset(set(corrected_read_splicing)) or read_attribute.rss_dis <= self.tss_cutoff:\n",
    "\t\t\t\t\t\t\t\tread_attribute.read_tag = 'Similar'\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tread_attribute.read_tag = 'Disqualify_NNC'\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tif read_attribute.rss_dis <= self.tss_cutoff or read_attribute.count  >= self.min_novel_trans_count:\n",
    "\t\t\t\t\t\t\t\tread_attribute.read_tag = 'Novel_loci'\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tread_attribute.read_tag = \"Disqualify_Other\"\n",
    "\t\t\t\n",
    "\t\t\trefined_multi_exon_read, read_attribute, loci_idx = self.secondary_refine(corrected_read_splicing, read_attribute, refined_multi_exon_read, loci_idx)\n",
    "\t\t\trefine_log[corrected_read_splicing] = read_attribute\n",
    "\t\treturn self.chrom, self.strand, refined_multi_exon_read, refine_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "class RefineWrapper:\n",
    "\tdef __init__(self, processed_collected_multi_exon_read, collected_single_exon_read, ref_mutple_exon_trans, ref_single_exon_trans, three_prime_exon, tss_dict, tss_cutoff, tes_cutoff, min_novel_trans_count, min_single_exon_coverage, min_single_exon_len, thread, tmp_dir):\n",
    "\t\tself.processed_collected_multi_exon_read = processed_collected_multi_exon_read\n",
    "\t\tself.collected_single_exon_read = collected_single_exon_read\n",
    "\t\tself.ref_mutple_exon_trans = ref_mutple_exon_trans\n",
    "\t\tself.ref_single_exon_trans = ref_single_exon_trans\n",
    "\t\tself.three_prime_exon = three_prime_exon\n",
    "\t\tself.tss_dict = tss_dict\n",
    "\t\tself.tss_cutoff = tss_cutoff\n",
    "\t\tself.tes_cutoff = tes_cutoff\n",
    "\t\tself.min_novel_trans_count = min_novel_trans_count\n",
    "\t\tself.min_single_exon_coverage = min_single_exon_coverage\n",
    "\t\tself.min_single_exon_len = min_single_exon_len\n",
    "\t\tself.thread = thread\n",
    "\t\tself.tmp_dir = tmp_dir\n",
    "\n",
    "\tdef run1(self):\n",
    "\t\tmulti_precompute_list = []\n",
    "\t\tfor (chrom, strand), chrand_processed_collected_multi_exon_read in self.processed_collected_multi_exon_read.items():\n",
    "\t\t\tmulti_precompute_list.append(MultiExonReadRefine(chrom, strand, chrand_processed_collected_multi_exon_read, self.ref_mutple_exon_trans[(chrom, strand)], self.tss_dict[(chrom, strand)], self.tss_cutoff, self.tes_cutoff, self.min_novel_trans_count))\n",
    "\t\twith Parallel(n_jobs = self.thread) as parallel:\n",
    "\t\t\tmulti_exon_results = parallel(delayed(lambda x:x.main_refine())(job) for job in multi_precompute_list)\n",
    "\n",
    "\t\treturn multi_exon_results\n",
    "\n",
    "\tdef run2(self):\n",
    "\t\tsingle_precompute_list = []\n",
    "\t\tfor (chrom, strand), chrand_collected_single_exon_read in self.collected_single_exon_read.items():\n",
    "\t\t\tsingle_precompute_list.append(SingleExonReadRefine(chrom, strand, chrand_collected_single_exon_read, self.ref_single_exon_trans[(chrom,strand)], self.ref_mutple_exon_trans[(chrom,strand)], self.three_prime_exon[(chrom,strand)], self.min_single_exon_coverage, self.min_single_exon_len))\n",
    "\t\twith Parallel(n_jobs = self.thread) as parallel:\n",
    "\t\t\tsingle_exon_results = parallel(delayed(lambda x:x.refine())(job) for job in single_precompute_list)\n",
    "\t\t\n",
    "\t\treturn single_exon_results\n",
    "\n",
    "\n",
    "\tdef result_collection(self):\n",
    "\t\tmulti_exon_results = self.run1()\n",
    "\t\tsingle_exon_results = self.run2()\n",
    "\t\tcollected_refined_isoforms = Vividict()\n",
    "\t\tpath_to_refine_log = f'{self.tmp_dir}/refine.log'\n",
    "\t\tfor result in sorted(multi_exon_results):\n",
    "\t\t\tchrom, strand, refined_multi_exon_read, refine_log = result\n",
    "\t\t\tfor corrected_read_splicing, read_attribute in refined_multi_exon_read.items():\n",
    "\t\t\t\tif strand == '-':\n",
    "\t\t\t\t\tcorrected_read_splicing = (read_attribute.end,) + corrected_read_splicing + (read_attribute.start,)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcorrected_read_splicing = (read_attribute.start,) + corrected_read_splicing + (read_attribute.end,)\n",
    "\t\t\t\tcollected_refined_isoforms[(chrom, strand)][corrected_read_splicing] = read_attribute\n",
    "\t\t\twith open(path_to_refine_log, 'a') as flog:\n",
    "\t\t\t\tfor corrected_read_splicing, read_attribute in refine_log.items():\n",
    "\t\t\t\t\tcorrected_read_splicing = ','.join([str(s) for s in corrected_read_splicing])\n",
    "\t\t\t\t\tread_attribute = read_attribute.__dict__\n",
    "\t\t\t\t\tread_attribute = '\\t'.join('{}: {}'.format(key, str(value)) for key, value in read_attribute.items())\n",
    "\t\t\t\t\tflog.write(f'{corrected_read_splicing}\\t{read_attribute}\\n')\n",
    "\t\tfor result in single_exon_results:\n",
    "\t\t\tchrom, strand, refined_single_exon_read = result\n",
    "\t\t\tfor corrected_read_splicing, read_attribute in refined_single_exon_read.items():\n",
    "\t\t\t\tcollected_refined_isoforms[(chrom, strand)][corrected_read_splicing] = read_attribute\n",
    "\t\t\n",
    "\t\tcollected_refined_isoforms = dict(sorted(collected_refined_isoforms.items()))\n",
    "\n",
    "\t\treturn collected_refined_isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
