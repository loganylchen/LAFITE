{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: collapsing.html\n",
    "title: read_collapsing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp read_collapsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass, field\n",
    "from time import strftime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from LAFITE.utils import loc_distance, Vividict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "@ dataclass\n",
    "class RawAttributeCollection:\n",
    "    name: str\n",
    "    start: int\n",
    "    end: int\n",
    "    fsm: bool = False\n",
    "    multi_exon: bool = True\n",
    "    correct_site: list = field(default_factory=list)\n",
    "    merge_gap: list = field(default_factory=list)\n",
    "    polyaed: bool = False\n",
    "    lowCredit_junction: dict = field(default_factory=dict)\n",
    "    splicing_tag: list = field(default_factory=list)\n",
    "    rss_dis: int = None\n",
    "    res_dis: int = None\n",
    "    collapsed_ID: str = None\n",
    "    reference_id: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "class ReadCorrectionColappse:\n",
    "    def __init__(self, chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window, mis_intron_length, polya_dict, corExcept_dis=0):\n",
    "        self.chrom = chrom\n",
    "        self.strand = strand\n",
    "        self.chrand_processed_read = chrand_processed_read\n",
    "        self.chrand_ref_exon = chrand_ref_exon\n",
    "        self.chrand_ref_junction = chrand_ref_junction\n",
    "        self.chrand_ref_single_exon_trans = chrand_ref_single_exon_trans\n",
    "        self.chrand_ref_mutple_exon_trans = chrand_ref_mutple_exon_trans\n",
    "        self.chrand_left_sj_set = chrand_left_sj_set\n",
    "        self.chrand_right_sj_set = chrand_right_sj_set\n",
    "        self.chrand_junction_dict = chrand_junction_dict\n",
    "        self.sj_correction_window = sj_correction_window\n",
    "        self.mis_intron_length = mis_intron_length\n",
    "        self.polya_dict = polya_dict\n",
    "        self.corExcept_dis = corExcept_dis\n",
    "\n",
    "    def single_exon_read_collapse(self, read, single_exon_read):\n",
    "        \"\"\"\n",
    "        remove the single-exon reads overlaped with exon from reference multi-exon transcript and collapse\"\"\"\n",
    "        start, end = read\n",
    "        if self.chrand_ref_exon:\n",
    "            overlapped_ref_exon = tuple(self.chrand_ref_exon.find(read))\n",
    "            if overlapped_ref_exon:\n",
    "                for exon in overlapped_ref_exon:\n",
    "                    if exon[0] <= start+self.sj_correction_window and exon[1] >= end-self.sj_correction_window:\n",
    "                        read = []\n",
    "                        break\n",
    "        if read:\n",
    "            counter = Counter(range(start, end+1))\n",
    "            for i in counter:\n",
    "                if i in single_exon_read:\n",
    "                    single_exon_read[i] += counter[i]\n",
    "                else:\n",
    "                    single_exon_read[i] = counter[i]\n",
    "\n",
    "        return single_exon_read\n",
    "\n",
    "    def RTS_refrence_distance(self, start, end, read_splicing):\n",
    "        \"\"\"calculate the distance between read start/end site to the reference transcript start/end site for FSM reads\n",
    "\n",
    "        Args:\n",
    "                strand (str): strand information\n",
    "                start (int): genomic start position regardless of strand\n",
    "                end (int): genomic end position regardless of strand\n",
    "                read_splicing (tuple): corrected read splicing\n",
    "                chrand_ref_mutple_exon_trans (dict): reference multi-exon transcript\n",
    "        \"\"\"\n",
    "        if self.strand == '+':\n",
    "            rss_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][0]-start)\n",
    "            res_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][1]-end)\n",
    "        else:\n",
    "            rss_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][0]-end)\n",
    "            res_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][1]-start)\n",
    "\n",
    "        return rss_dis, res_dis\n",
    "\n",
    "    def multi_exon_read_correction(self, read_id, full_block):\n",
    "        \"\"\"\n",
    "        splicing junction correction and collaspsing for multi-exon read\"\"\"\n",
    "\n",
    "        raw_splicing = tuple(full_block[1:-1])\n",
    "        raw_read_attribute = RawAttributeCollection(\n",
    "            read_id, full_block[0], full_block[-1])\n",
    "        corrected_read_splicing = []\n",
    "\n",
    "        # polya event checking\n",
    "        try:\n",
    "            if self.polya_dict[read_id]:\n",
    "                raw_read_attribute.polyaed = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if raw_splicing in self.chrand_ref_mutple_exon_trans:  # raw read_splicing matching with the reference\n",
    "            raw_read_attribute.fsm = True\n",
    "            raw_read_attribute.splicing_tag = 'FSM'\n",
    "            corrected_read_splicing = raw_splicing\n",
    "            raw_read_attribute.rss_dis, raw_read_attribute.res_dis = self.RTS_refrence_distance(\n",
    "                raw_read_attribute.start, raw_read_attribute.end, corrected_read_splicing)\n",
    "\n",
    "        else:  # splicing site correction\n",
    "            itered_raw_splicing = iter(raw_splicing)\n",
    "            for idx, (left_sj, right_sj) in enumerate(zip(itered_raw_splicing, itered_raw_splicing)):\n",
    "\n",
    "                # check splicing coverage and motif in raw data\n",
    "                sj_pos = full_block.index(left_sj)\n",
    "                tmp_sj = (self.chrom, self.strand, left_sj, right_sj)\n",
    "                junction_coverage = self.chrand_junction_dict[tmp_sj][0]\n",
    "                junction_motif = self.chrand_junction_dict[tmp_sj][2]\n",
    "\n",
    "                if left_sj in self.chrand_left_sj_set and right_sj in self.chrand_right_sj_set:\n",
    "                    if (left_sj, right_sj) in self.chrand_ref_junction:\n",
    "                        raw_read_attribute.splicing_tag.append('M')\n",
    "                    else:\n",
    "                        raw_read_attribute.splicing_tag.append('KC')\n",
    "\n",
    "                elif self.chrand_left_sj_set:\n",
    "                    left_dis, left_ref_sj = loc_distance(\n",
    "                        self.chrand_left_sj_set, left_sj)\n",
    "                    right_dis, right_ref_sj = loc_distance(\n",
    "                        self.chrand_right_sj_set, right_sj)\n",
    "\n",
    "                    # do not correct the splicing site once the edit distance > sj_correction_window\n",
    "                    if left_dis > self.sj_correction_window:\n",
    "                        left_ref_sj = left_sj\n",
    "                    if right_dis > self.sj_correction_window:\n",
    "                        right_ref_sj = right_sj\n",
    "\n",
    "                    # correction exception, splicing junction with edit distance less than the given value for both sides\n",
    "                    if self.corExcept_dis and left_dis <= self.corExcept_dis and right_dis <= self.corExcept_dis and junction_coverage > 1 and junction_motif == 'canonical':\n",
    "                        raw_read_attribute.splicing_tag.append('EXC')\n",
    "\n",
    "                    # splicing site correction\n",
    "                    elif left_dis <= self.sj_correction_window or right_dis <= self.sj_correction_window:\n",
    "                        if [left_sj, right_sj] == [left_ref_sj, right_ref_sj]:\n",
    "                            pass\n",
    "                        elif full_block[sj_pos-1] < left_ref_sj < right_ref_sj < full_block[sj_pos+2]:\n",
    "                            raw_read_attribute.correct_site.append(\n",
    "                                [left_sj, right_sj])\n",
    "                            left_sj, right_sj = left_ref_sj, right_ref_sj\n",
    "\n",
    "                        if left_sj in self.chrand_left_sj_set and right_sj in self.chrand_right_sj_set:\n",
    "                            if (left_sj, right_sj) in self.chrand_ref_junction:\n",
    "                                raw_read_attribute.splicing_tag.append('CM')\n",
    "                            else:\n",
    "                                raw_read_attribute.splicing_tag.append('CKC')\n",
    "\n",
    "                # checking unintended small intron overlap with reference exons\n",
    "                if len(raw_read_attribute.splicing_tag) == idx and right_sj - left_sj <= self.mis_intron_length:\n",
    "                    if self.chrand_ref_exon:\n",
    "                        overlapped_ref_exon = tuple(\n",
    "                            self.chrand_ref_exon.find((left_sj, right_sj)))\n",
    "                    else:\n",
    "                        overlapped_ref_exon = ()\n",
    "                    # compare the unintended intron with the ref_exon from multi-exon transcripts\n",
    "                    if idx == 0 and overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if (len(full_block) == 4 and exon[1] >= right_sj and exon[0] <= left_sj):\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                raw_read_attribute.multi_exon = False\n",
    "                                break\n",
    "                            elif (exon[1] == full_block[sj_pos+2] and exon[0] <= left_sj):\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                break\n",
    "\n",
    "                    elif idx == int(len(raw_splicing)/2 - 1) and overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if exon[1] >= right_sj and exon[0] == full_block[sj_pos-1]:\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                break\n",
    "\n",
    "                    elif 0 < idx < int(len(raw_splicing)/2 - 1) and overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if exon[1] == full_block[sj_pos+2] and exon[0] == full_block[sj_pos-1]:\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                break\n",
    "\n",
    "                    # compare the unintended intron with the exon from single-exon transcripts\n",
    "                    elif not overlapped_ref_exon and len(full_block) == 4:\n",
    "                        if self.chrand_ref_single_exon_trans:\n",
    "                            overlapped_ref_exon = tuple(\n",
    "                                self.chrand_ref_single_exon_trans.find((left_sj, right_sj)))\n",
    "\n",
    "                        if overlapped_ref_exon:\n",
    "                            for exon in overlapped_ref_exon:\n",
    "                                if exon[1] >= right_sj and exon[0] <= left_sj:\n",
    "                                    raw_read_attribute.merge_gap.append(\n",
    "                                        [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                    raw_read_attribute.multi_exon = False\n",
    "                                    break\n",
    "\n",
    "                corrected_read_splicing.extend([left_sj, right_sj])\n",
    "\n",
    "                if [full_block[sj_pos], full_block[sj_pos+1]] in raw_read_attribute.merge_gap:\n",
    "                    raw_read_attribute.splicing_tag.append('UI')\n",
    "                    del corrected_read_splicing[-2:]\n",
    "\n",
    "                elif len(raw_read_attribute.splicing_tag) == idx:\n",
    "                    raw_read_attribute.splicing_tag.append('NC')\n",
    "                    if junction_coverage == 1:\n",
    "                        raw_read_attribute.lowCredit_junction[idx +\n",
    "                                                              1] = junction_motif\n",
    "\n",
    "            corrected_read_splicing = tuple(corrected_read_splicing)\n",
    "            if corrected_read_splicing in self.chrand_ref_mutple_exon_trans:\n",
    "                raw_read_attribute.fsm = True\n",
    "                raw_read_attribute.rss_dis, raw_read_attribute.res_dis = self.RTS_refrence_distance(\n",
    "                    raw_read_attribute.start, raw_read_attribute.end, corrected_read_splicing)\n",
    "                raw_read_attribute.reference_id = self.chrand_ref_mutple_exon_trans[\n",
    "                    corrected_read_splicing][2]\n",
    "\n",
    "        return corrected_read_splicing, raw_read_attribute\n",
    "\n",
    "    def multi_exon_read_collapse(self, corrected_read_splicing, raw_read_attribute, rss_dis_lst, res_dis_lst, multi_exon_read, collapsed_idx):\n",
    "        \"\"\"collapsing multi-exon read\n",
    "        \"\"\"\n",
    "        prefix = 'POS' if self.strand == '+' else 'NEG'\n",
    "        if raw_read_attribute.lowCredit_junction:\n",
    "            pass\n",
    "        elif corrected_read_splicing:\n",
    "            if corrected_read_splicing not in multi_exon_read:\n",
    "                collapsed_idx += 1\n",
    "                raw_read_attribute.collapsed_ID = f'{self.chrom}_{prefix}.{collapsed_idx}'\n",
    "                multi_exon_read[corrected_read_splicing] = [[raw_read_attribute.start], [raw_read_attribute.end], [\n",
    "                    raw_read_attribute.polyaed], 1, raw_read_attribute.fsm, raw_read_attribute.collapsed_ID, [raw_read_attribute.reference_id]]\n",
    "            else:\n",
    "                multi_exon_read[corrected_read_splicing][0].insert(\n",
    "                    0, raw_read_attribute.start)\n",
    "                multi_exon_read[corrected_read_splicing][1].insert(\n",
    "                    0, raw_read_attribute.end)\n",
    "                multi_exon_read[corrected_read_splicing][2].insert(\n",
    "                    0, raw_read_attribute.polyaed)\n",
    "                multi_exon_read[corrected_read_splicing][3] += 1\n",
    "\n",
    "                raw_read_attribute.collapsed_ID = multi_exon_read[corrected_read_splicing][5]\n",
    "                multi_exon_read[corrected_read_splicing][6].insert(\n",
    "                    0, raw_read_attribute.reference_id)\n",
    "\n",
    "        if raw_read_attribute.rss_dis:\n",
    "            rss_dis_lst.append(raw_read_attribute.rss_dis)\n",
    "            res_dis_lst.append(raw_read_attribute.res_dis)\n",
    "        # print(len(multi_exon_read[corrected_read_splicing]))\n",
    "        return multi_exon_read, rss_dis_lst, res_dis_lst, collapsed_idx, raw_read_attribute\n",
    "\n",
    "    def coco_operation(self, collapsed_idx=0):\n",
    "        \"\"\"main function for correcting splicing junction and collpasing reads\n",
    "        \"\"\"\n",
    "        corrected_read = defaultdict(dict)\n",
    "        correction_log = defaultdict(dict)\n",
    "        single_exon_read = defaultdict(dict)\n",
    "        multi_exon_read = defaultdict(dict)\n",
    "        rss_dis_lst = []\n",
    "        res_dis_lst = []\n",
    "\n",
    "        for read_id, full_block in tqdm(self.chrand_processed_read.items(), desc=f'{strftime(\"%Y-%m-%d %H:%M:%S\")}: Collapsing raw reads from {self.chrom} {self.strand}'):\n",
    "\n",
    "            # single-exon read collapsing\n",
    "            if len(full_block) == 2:\n",
    "                single_exon_read = self.single_exon_read_collapse(\n",
    "                    full_block, single_exon_read)\n",
    "                corrected_read[read_id] = full_block\n",
    "            # multi-exon read correction and collapsing\n",
    "            else:\n",
    "                corrected_read_splicing, raw_read_attribute = self.multi_exon_read_correction(\n",
    "                    read_id, full_block)\n",
    "                multi_exon_read, rss_dis_lst, res_dis_lst, collapsed_idx, raw_read_attribute = self.multi_exon_read_collapse(\n",
    "                    corrected_read_splicing, raw_read_attribute, rss_dis_lst, res_dis_lst, multi_exon_read, collapsed_idx)\n",
    "\n",
    "                if corrected_read_splicing:\n",
    "                    corrected_read[read_id] = [\n",
    "                        raw_read_attribute.start, *list(corrected_read_splicing), raw_read_attribute.end]\n",
    "                else:\n",
    "                    corrected_read[read_id] = [\n",
    "                        raw_read_attribute.start, raw_read_attribute.end]\n",
    "                correction_log[read_id] = raw_read_attribute\n",
    "\n",
    "        return self.chrom, self.strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = '/expt/zjzace/Nanopore_subcellular/Reference/gencode.v38.primary_assembly.annotation.sorted.gtf'\n",
    "ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans, left_sj_set, right_sj_set, tss_dict = RefProcessWrapper(\n",
    "    gtf, 16).result_collection()\n",
    "bed = '/expt/zjzace/Nanopore_subcellular/Analysis/Assembly/LAFITE/GLRA_tmp/A549_Cyto_LAFITE_tmp/bam.bed'\n",
    "fa = '/NFS/mnemosyne2/expt/zjzace/GenomeRef/GRCh38.primary_assembly.genome.fa'\n",
    "junction_dict, processed_read = read_grouping(bed, fa)\n",
    "polya_dict = polya_signal_import(\n",
    "    '/expt/zjzace/Nanopore_subcellular/Analysis/Nanopolish/A549_Cyto_PolyA.res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:04:51: Collapsing raw reads from chr19 -: 100%|██████████| 48521/48521 [00:05<00:00, 9070.96it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "chrom, strand = 'chr19', '-'\n",
    "chrand_processed_read = processed_read[(chrom, strand)]\n",
    "chrand_ref_exon = ref_exon[(chrom, strand)]\n",
    "chrand_ref_junction = ref_junction[(chrom, strand)]\n",
    "chrand_ref_single_exon_trans = ref_single_exon_trans[(chrom, strand)]\n",
    "chrand_ref_mutple_exon_trans = ref_mutple_exon_trans[(chrom, strand)]\n",
    "chrand_left_sj_set = left_sj_set[(chrom, strand)]\n",
    "chrand_right_sj_set = right_sj_set[(chrom, strand)]\n",
    "chrand_junction_dict = junction_dict[(chrom, strand)]\n",
    "sj_correction_window = 40\n",
    "mis_intron_length = 150\n",
    "corExcept_dis = 4\n",
    "polya_dict = polya_dict\n",
    "chrom, strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst = ReadCorrectionColappse(\n",
    "    chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window, mis_intron_length, polya_dict, corExcept_dis).coco_operation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "class CoCoWrapper:\n",
    "    def __init__(self, thread, processed_read, ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans, left_sj_set, right_sj_set, junction_dict, sj_correction_window, polya_dict, mis_intron_length, tmp_dir, corExcept_dis=0):\n",
    "        self.thread = thread\n",
    "        self.processed_read = processed_read\n",
    "        self.ref_exon = ref_exon\n",
    "        self.ref_junction = ref_junction\n",
    "        self.ref_single_exon_trans = ref_single_exon_trans\n",
    "        self.ref_mutple_exon_trans = ref_mutple_exon_trans\n",
    "        self.left_sj_set = left_sj_set\n",
    "        self.right_sj_set = right_sj_set\n",
    "        self.junction_dict = junction_dict\n",
    "        self.sj_correction_window = sj_correction_window\n",
    "        self.polya_dict = polya_dict\n",
    "        self.mis_intron_length = mis_intron_length\n",
    "        self.tmp_dir = tmp_dir\n",
    "        self.corExcept_dis = corExcept_dis\n",
    "\n",
    "    def job_compute(self):\n",
    "\n",
    "        job = []\n",
    "        for branch in self.processed_read:\n",
    "            chrom, strand = branch\n",
    "            chrand_processed_read = self.processed_read[branch]\n",
    "            chrand_ref_exon = self.ref_exon[branch]\n",
    "            chrand_ref_junction = self.ref_junction[branch]\n",
    "            chrand_ref_single_exon_trans = self.ref_single_exon_trans[branch]\n",
    "            chrand_ref_mutple_exon_trans = self.ref_mutple_exon_trans[branch]\n",
    "            chrand_left_sj_set = self.left_sj_set[branch]\n",
    "            chrand_right_sj_set = self.right_sj_set[branch]\n",
    "            chrand_junction_dict = self.junction_dict[branch]\n",
    "            job.append(ReadCorrectionColappse(chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans,\n",
    "                                              chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, self.sj_correction_window, self.mis_intron_length, self.polya_dict, self.corExcept_dis))\n",
    "        p = Pool(processes=self.thread)\n",
    "        result = [p.apply_async(i.coco_operation, args=()) for i in job]\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def result_collection(self):\n",
    "        collected_single_exon_read = Vividict()\n",
    "        collected_multi_exon_read = Vividict()\n",
    "        collected_rss = []\n",
    "        collected_res = []\n",
    "        path_to_log = f'{self.tmp_dir}/read_correction.log'\n",
    "        path_to_corrected_bed = f'{self.tmp_dir}/Corrected_reads.bed'\n",
    "\n",
    "        result = self.job_compute()\n",
    "        with open(path_to_log, 'w') as flog, open(path_to_corrected_bed, 'w') as fbed:\n",
    "            for res in result:\n",
    "                chrom, strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst = res.get()\n",
    "\n",
    "                collected_single_exon_read[(chrom, strand)] = single_exon_read\n",
    "                collected_multi_exon_read[(chrom, strand)] = multi_exon_read\n",
    "                collected_rss.extend(rss_dis_lst)\n",
    "                collected_res.extend(res_dis_lst)\n",
    "                for read_id, raw_read_attribute in correction_log.items():\n",
    "                    raw_read_attribute.name = raw_read_attribute.name.split('_', 1)[\n",
    "                        1]\n",
    "                    attributes = '\\t'.join('{}: {}'.format(\n",
    "                        key, value) for key, value in raw_read_attribute.__dict__.items())\n",
    "                    flog.write(f'{attributes}\\n')\n",
    "\n",
    "                for read_id, full_block in corrected_read.items():\n",
    "                    read_name = read_id.split('_', 1)[1]\n",
    "                    bed_block = splicing_to_bed_block(\n",
    "                        chrom, strand, read_name, full_block)\n",
    "                    fbed.write(f'{bed_block}\\n')\n",
    "        return collected_single_exon_read, collected_multi_exon_read, collected_rss, collected_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV4 +: 100%|██████████| 2661/2661 [00:00<00:00, 91686.87it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV5 -: 100%|██████████| 590/590 [00:00<00:00, 12759.49it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV6 -: 100%|██████████| 1364/1364 [00:00<00:00, 10556.48it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV2 +: 100%|██████████| 4088/4088 [00:00<00:00, 6357.57it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV1 +: 100%|██████████| 3615/3615 [00:01<00:00, 2790.63it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV2 -: 100%|██████████| 6835/6835 [00:01<00:00, 5238.81it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV4 -: 100%|██████████| 7002/7002 [00:01<00:00, 5559.16it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV1 -: 100%|██████████| 7764/7764 [00:01<00:00, 5626.42it/s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV7 -: 100%|██████████| 7413/7413 [00:01<00:00, 6001.32it/s]s]\n",
      "2022-04-12 19:18:26: Collapsing raw reads from SIRV3 -: 100%|██████████| 2899/2899 [00:01<00:00, 1956.22it/s]s]\n",
      "2022-04-12 19:18:28: Collapsing raw reads from SIRV3 +: 100%|██████████| 10834/10834 [00:00<00:00, 79545.93it/s]\n",
      "2022-04-12 19:18:27: Collapsing raw reads from SIRV5 +: 100%|██████████| 20402/20402 [00:00<00:00, 29591.10it/s]\n",
      "2022-04-12 19:18:28: Collapsing raw reads from SIRV6 +: 100%|██████████| 32687/32687 [00:01<00:00, 30373.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from LAFITE.reference_processing import RefProcessWrapper, short_reads_sj_import\n",
    "from LAFITE.preprocessing import read_grouping, polya_signal_import, PolyAFinder\n",
    "from LAFITE.utils import temp_dir_creation, bam2bed, keep_tmp_file\n",
    "gtf = '/expt/zjzace/Nanopore_subcellular/SIRV/SIRV_Set1/Raw_data/SIRV_isoforms_multi-fasta-annotation_C_170612a.gtf'\n",
    "bed = '/expt/zjzace/Nanopore_subcellular/SIRV/SIRV_Set1/bam/SRR6058584.sorted.bed'\n",
    "fa = '/expt/zjzace/Nanopore_subcellular/SIRV/SIRV_Set1/Raw_data/SIRV_isoforms_multi-fasta_170612a.fasta'\n",
    "junction_dict, processed_read = read_grouping(bed, fa)\n",
    "ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans, left_sj_set, right_sj_set, tss_dict = RefProcessWrapper(\n",
    "    gtf, 16).result_collection()\n",
    "\n",
    "# polya_dict = polya_signal_import('/expt/zjzace/Nanopore_subcellular/SIRV/SIRV_Set1/bam/SRR6058584.polya.res')\n",
    "polya_dict = PolyAFinder(\n",
    "    processed_read, fa, '/home/zjzace/software/SQANTI3-4.1/data/polyA_motifs/mouse_and_human.polyA_motif.txt').polya_estimation()\n",
    "collected_single_exon_read, collected_multi_exon_read, tss, tes = CoCoWrapper(16, processed_read, ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans,\n",
    "                                                                              left_sj_set, right_sj_set, junction_dict, sj_correction_window=40, polya_dict=polya_dict, mis_intron_length=150, tmp_dir='.', corExcept_dis=4).result_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def single_exon_read_collapse(read, chrand_ref_exon, overhang, single_exon_read):\n",
    "    \"\"\"remove the single-exon reads overlaped with exon from reference multi-exon transcript and collapse\n",
    "\n",
    "    Args:\n",
    "            read (list): start and end position of the single-exon read (1 base, [1,100])\n",
    "            chrand_ref_exon (interlap data): exon from reference multi-exon transcript\n",
    "            overhang (int): tolerance distance\n",
    "            single_exon_read (dict): returned collapsed single-exon reads\n",
    "    \"\"\"\n",
    "\n",
    "    start, end = read\n",
    "    if chrand_ref_exon:\n",
    "        overlapped_ref_exon = tuple(chrand_ref_exon.find(read))\n",
    "        if overlapped_ref_exon:\n",
    "            for exon in overlapped_ref_exon:\n",
    "                if exon[0] <= start+overhang and exon[1] >= end-overhang:\n",
    "                    read = []\n",
    "                    break\n",
    "    if read:\n",
    "        counter = Counter(range(start, end+1))\n",
    "        for i in counter:\n",
    "            if i in single_exon_read:\n",
    "                single_exon_read[i] += counter[i]\n",
    "            else:\n",
    "                single_exon_read[i] = counter[i]\n",
    "\n",
    "    return single_exon_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def RTS_refrence_distance(strand, start, end, read_splicing, chrand_ref_mutple_exon_trans):\n",
    "    \"\"\"calculate the distance between read start/end site to the reference transcript start/end site for FSM reads\n",
    "\n",
    "    Args:\n",
    "            strand (str): strand information\n",
    "            start (int): genomic start position regardless of strand\n",
    "            end (int): genomic end position regardless of strand\n",
    "            read_splicing (tuple): corrected read splicing\n",
    "            chrand_ref_mutple_exon_trans (dict): reference multi-exon transcript\n",
    "    \"\"\"\n",
    "    if strand == '+':\n",
    "        rss_dis = abs(chrand_ref_mutple_exon_trans[read_splicing][0]-start)\n",
    "        res_dis = abs(chrand_ref_mutple_exon_trans[read_splicing][1]-end)\n",
    "    else:\n",
    "        rss_dis = abs(chrand_ref_mutple_exon_trans[read_splicing][0]-end)\n",
    "        res_dis = abs(chrand_ref_mutple_exon_trans[read_splicing][1]-start)\n",
    "\n",
    "    return rss_dis, res_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def multi_exon_read_correction(chrom, strand, name, full_block, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window, mis_intron_length, corExcept_dis, polya_dict):\n",
    "    \"\"\"splicing junction correction and collaspsing for multi-exon read\n",
    "\n",
    "    Args:\n",
    "            chrom (str): chromosome\n",
    "            strand (str): strand information\n",
    "            name (str): read name\n",
    "            full_block (list): start, end position and all splicing site of multi-exon read (1 base, [1,20,40, 100])\n",
    "            chrand_ref_exon (interlap data): exon from reference multi-exon transcript\n",
    "            chrand_ref_junction (list): reference splicing junction\n",
    "            chrand_ref_single_exon_trans (interlap data): reference single-exon transcript\n",
    "            chrand_ref_mutple_exon_trans (dict): reference multi-exon transcript\n",
    "            chrand_left_sj_set (list): reference left splicing site\n",
    "            chrand_right_sj_set (list): reference right splicing site\n",
    "            chrand_junction_dict (dict): splicing junction detected from long read\n",
    "            sj_correction_window (int): tolerance distance for splicing site correction\n",
    "            mis_intron_length (int): unintended small intron gap that should be filled\n",
    "            corExcept_dis (int, optional): edit distance to the reference splicing site\n",
    "            polya_dict (dict, optional): raw long reads Polyadenylation event\n",
    "    \"\"\"\n",
    "\n",
    "    raw_splicing = tuple(full_block[1:-1])\n",
    "    start, end = full_block[0], full_block[-1]\n",
    "    corrected_read_splicing = []\n",
    "    tag_dict = {'reference_match': False, 'multi-exon': True, 'correct_site': [], 'merge_site': [],\n",
    "                'polya_signal': False, 'lowCredit_junction': {}, 'splicing_tag': [], 'rss_dis': None, 'res_dis': None}\n",
    "\n",
    "    # polya event checking\n",
    "    try:\n",
    "        if polya_dict[name]:\n",
    "            tag_dict['polya_signal'] = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if raw_splicing in chrand_ref_mutple_exon_trans:  # uncorrected read_splicing matching with the reference\n",
    "        tag_dict['reference_match'] = True\n",
    "        tag_dict['splicing_tag'] = 'FSM'\n",
    "        corrected_read_splicing = raw_splicing\n",
    "        tag_dict['rss_dis'], tag_dict['res_dis'] = RTS_refrence_distance(\n",
    "            strand, start, end, corrected_read_splicing, chrand_ref_mutple_exon_trans)\n",
    "\n",
    "    else:  # splicing site correction\n",
    "        itered_raw_splicing = iter(raw_splicing)\n",
    "        for idx, (left_sj, right_sj) in enumerate(zip(itered_raw_splicing, itered_raw_splicing)):\n",
    "\n",
    "            # check splicing coverage and motif in raw data\n",
    "            sj_pos = full_block.index(left_sj)\n",
    "            tmp_sj = (chrom, strand, left_sj, right_sj)\n",
    "            junction_coverage = chrand_junction_dict[tmp_sj][0]\n",
    "            junction_motif = chrand_junction_dict[tmp_sj][2]\n",
    "\n",
    "            if left_sj in chrand_left_sj_set and right_sj in chrand_right_sj_set:\n",
    "                if (left_sj, right_sj) in chrand_ref_junction:\n",
    "                    tag_dict['splicing_tag'].append('M')\n",
    "                else:\n",
    "                    tag_dict['splicing_tag'].append('KC')\n",
    "\n",
    "            elif chrand_left_sj_set:\n",
    "                left_dis, left_ref_sj = loc_distance(\n",
    "                    chrand_left_sj_set, left_sj)\n",
    "                right_dis, right_ref_sj = loc_distance(\n",
    "                    chrand_right_sj_set, right_sj)\n",
    "\n",
    "                # do not correct the splicing site once the edit distance > sj_correction_window\n",
    "                if left_dis > sj_correction_window:\n",
    "                    left_ref_sj = left_sj\n",
    "                if right_dis > sj_correction_window:\n",
    "                    right_ref_sj = right_sj\n",
    "\n",
    "                # correction exception, splicing junction with edit distance less than 4 for both sides\n",
    "                if left_dis <= corExcept_dis and right_dis <= corExcept_dis and junction_coverage > 1 and junction_motif == 'canonical':\n",
    "                    tag_dict['splicing_tag'].append('EXC')\n",
    "\n",
    "                # splicing site correction\n",
    "                elif left_dis <= sj_correction_window or right_dis <= sj_correction_window:\n",
    "                    if [left_sj, right_sj] == [left_ref_sj, right_ref_sj]:\n",
    "                        pass\n",
    "                    elif full_block[sj_pos-1] < left_ref_sj < right_ref_sj < full_block[sj_pos+2]:\n",
    "                        tag_dict['correct_site'].append([left_sj, right_sj])\n",
    "                        left_sj, right_sj = left_ref_sj, right_ref_sj\n",
    "\n",
    "                    if left_sj in chrand_left_sj_set and right_sj in chrand_right_sj_set:\n",
    "                        if (left_sj, right_sj) in chrand_ref_junction:\n",
    "                            tag_dict['splicing_tag'].append('CM')\n",
    "                        else:\n",
    "                            tag_dict['splicing_tag'].append('CKC')\n",
    "\n",
    "            # checking unintended small intron overlap with reference exons\n",
    "            if len(tag_dict['splicing_tag']) == idx and right_sj - left_sj <= mis_intron_length:\n",
    "                if chrand_ref_exon:\n",
    "                    overlapped_ref_exon = tuple(\n",
    "                        chrand_ref_exon.find((left_sj, right_sj)))\n",
    "                else:\n",
    "                    overlapped_ref_exon = ()\n",
    "                # compare the unintended intron with the ref_exon from multi-exon transcripts\n",
    "                if idx == 0 and overlapped_ref_exon:\n",
    "                    for exon in overlapped_ref_exon:\n",
    "                        if (len(full_block) == 4 and exon[1] >= right_sj and exon[0] <= left_sj):\n",
    "                            tag_dict['merge_site'].append(\n",
    "                                [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                            tag_dict['multi-exon'] = False\n",
    "                            break\n",
    "                        elif (exon[1] == full_block[sj_pos+2] and exon[0] <= left_sj):\n",
    "                            tag_dict['merge_site'].append(\n",
    "                                [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                            break\n",
    "\n",
    "                elif idx == int(len(raw_splicing)/2 - 1) and overlapped_ref_exon:\n",
    "                    for exon in overlapped_ref_exon:\n",
    "                        if exon[1] >= right_sj and exon[0] == full_block[sj_pos-1]:\n",
    "                            tag_dict['merge_site'].append(\n",
    "                                [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                            break\n",
    "\n",
    "                elif 0 < idx < int(len(raw_splicing)/2 - 1) and overlapped_ref_exon:\n",
    "                    for exon in overlapped_ref_exon:\n",
    "                        if exon[1] == full_block[sj_pos+2] and exon[0] == full_block[sj_pos-1]:\n",
    "                            tag_dict['merge_site'].append(\n",
    "                                [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                            break\n",
    "\n",
    "                # compare the unintended intron with the exon from single-exon transcripts\n",
    "                elif not overlapped_ref_exon and len(full_block) == 4:\n",
    "                    if chrand_ref_single_exon_trans:\n",
    "                        overlapped_ref_exon = tuple(\n",
    "                            chrand_ref_single_exon_trans.find((left_sj, right_sj)))\n",
    "\n",
    "                    if overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if exon[1] >= right_sj and exon[0] <= left_sj:\n",
    "                                tag_dict['merge_site'].append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                tag_dict['multi-exon'] = False\n",
    "                                break\n",
    "\n",
    "            corrected_read_splicing.extend([left_sj, right_sj])\n",
    "\n",
    "            if [full_block[sj_pos], full_block[sj_pos+1]] in tag_dict['merge_site']:\n",
    "                tag_dict['splicing_tag'].append('UI')\n",
    "                del corrected_read_splicing[-2:]\n",
    "\n",
    "            elif len(tag_dict['splicing_tag']) == idx:\n",
    "                tag_dict['splicing_tag'].append('NC')\n",
    "                if junction_coverage == 1:\n",
    "                    tag_dict['lowCredit_junction'][idx+1] = junction_motif\n",
    "\n",
    "        corrected_read_splicing = tuple(corrected_read_splicing)\n",
    "        if corrected_read_splicing in chrand_ref_mutple_exon_trans:\n",
    "            tag_dict['reference_match'] = True\n",
    "            tag_dict['rss_dis'], tag_dict['res_dis'] = RTS_refrence_distance(\n",
    "                strand, start, end, corrected_read_splicing, chrand_ref_mutple_exon_trans)\n",
    "\n",
    "    return start, end, corrected_read_splicing, tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def multi_exon_read_collapse(read_id, start, end, corrected_read_splicing, tag_dict, rss_dis_lst, res_dis_lst, multi_exon_read, collapsed_idx):\n",
    "    \"\"\"collapsing multi-exon read\n",
    "    \"\"\"\n",
    "    read_name = read_id.split('_', 1)[1]\n",
    "    if tag_dict['lowCredit_junction']:\n",
    "        pass\n",
    "    elif corrected_read_splicing:\n",
    "        if corrected_read_splicing not in multi_exon_read:\n",
    "            collapsed_idx += 1\n",
    "            multi_exon_read[corrected_read_splicing] = [[start], [end], [tag_dict['polya_signal']], 1, [\n",
    "                read_name], tag_dict['reference_match'], f'collapsed.{collapsed_idx}']\n",
    "        else:\n",
    "            multi_exon_read[corrected_read_splicing][0].insert(0, start)\n",
    "            multi_exon_read[corrected_read_splicing][1].insert(0, end)\n",
    "            multi_exon_read[corrected_read_splicing][2].insert(\n",
    "                0, tag_dict['polya_signal'])\n",
    "            multi_exon_read[corrected_read_splicing][3] += 1\n",
    "            multi_exon_read[corrected_read_splicing][4].insert(0, read_name)\n",
    "\n",
    "    if tag_dict['rss_dis']:\n",
    "        rss_dis_lst.append(tag_dict['rss_dis'])\n",
    "        res_dis_lst.append(tag_dict['res_dis'])\n",
    "\n",
    "    return multi_exon_read, rss_dis_lst, res_dis_lst, collapsed_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def three_prime_exon_extraction(strand, multi_exon_read):\n",
    "    three_prime_exon = defaultdict(set)\n",
    "    for corrected_read_splicing, read_info in multi_exon_read.items():\n",
    "        if strand == '+':\n",
    "            max_end = max(read_info[1])\n",
    "            exon = (corrected_read_splicing[-1], max_end)\n",
    "        else:\n",
    "            max_end = max(read_info[0])\n",
    "            exon = (max_end, corrected_read_splicing[0])\n",
    "        three_prime_exon.add(exon)\n",
    "\n",
    "    return three_prime_exon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def coco_operation(chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window=40, mis_intron_length=150, corExcept_dis=0, polya_dict=None, collapsed_idx=0):\n",
    "    \"\"\"main function for correcting splicing junction and collpasing reads\n",
    "    \"\"\"\n",
    "    corrected_read = defaultdict(dict)\n",
    "    correction_log = defaultdict(dict)\n",
    "    single_exon_read = defaultdict(dict)\n",
    "    multi_exon_read = defaultdict(dict)\n",
    "    rss_dis_lst = res_dis_lst = []\n",
    "\n",
    "    for read_id, full_block in tqdm(chrand_processed_read.items(), desc=f'{strftime(\"%Y-%m-%d %H:%M:%S\")}: Collapsing raw reads from {chrom} {strand}'):\n",
    "\n",
    "        # single-exon read collapsing\n",
    "        if len(full_block) == 2:\n",
    "            single_exon_read = single_exon_read_collapse(\n",
    "                full_block, chrand_ref_exon, sj_correction_window, single_exon_read)\n",
    "            corrected_read[read_id] = full_block\n",
    "        # multi-exon read correction and collapsing\n",
    "        else:\n",
    "            start, end, corrected_read_splicing, tag_dict = multi_exon_read_correction(chrom, strand, read_id, full_block, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans,\n",
    "                                                                                       chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window, mis_intron_length, corExcept_dis, polya_dict)\n",
    "\n",
    "            multi_exon_read, rss_dis_lst, res_dis_lst, collapsed_idx = multi_exon_read_collapse(\n",
    "                read_id, start, end, corrected_read_splicing, tag_dict, rss_dis_lst, res_dis_lst, multi_exon_read, collapsed_idx)\n",
    "            if corrected_read_splicing:\n",
    "                corrected_read[read_id] = [\n",
    "                    start, *list(corrected_read_splicing), end]\n",
    "            else:\n",
    "                corrected_read[read_id] = [start, end]\n",
    "            correction_log[read_id] = tag_dict\n",
    "\n",
    "    return chrom, strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "def splicing_to_bed_block(chrom, strand, name, full_block):\n",
    "    start, end = full_block[0], full_block[-1]\n",
    "    full_block = iter(full_block)\n",
    "    block_sizes = []\n",
    "    block_starts = []\n",
    "    for left_end, right_end in zip(full_block, full_block):\n",
    "        block_starts.append(left_end - start)\n",
    "        block_sizes.append(right_end - left_end + 1)\n",
    "    block_count = len(block_sizes)\n",
    "    block_sizes = ','.join([str(i) for i in block_sizes])\n",
    "    block_starts = ','.join([str(i) for i in block_starts])\n",
    "    bed_block = [chrom, start-1, end, name, '-', strand, start -\n",
    "                 1, end, '255,0,0', block_count, block_sizes, block_starts]\n",
    "    bed_block = '\\t'.join([str(i) for i in bed_block])\n",
    "\n",
    "    return bed_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CoCoWrapper:\n",
    "    def __init__(self, thread, processed_read, ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans, left_sj_set, right_sj_set, junction_dict, tmp_dir, sj_correction_window, polya_dict, mis_intron_length, corExcept_dis=4):\n",
    "        self.thread = thread\n",
    "        self.processed_read = processed_read\n",
    "        self.ref_exon = ref_exon\n",
    "        self.ref_junction = ref_junction\n",
    "        self.ref_single_exon_trans = ref_single_exon_trans\n",
    "        self.ref_mutple_exon_trans = ref_mutple_exon_trans\n",
    "        self.left_sj_set = left_sj_set\n",
    "        self.right_sj_set = right_sj_set\n",
    "        self.junction_dict = junction_dict\n",
    "        self.sj_correction_window = sj_correction_window\n",
    "        self.tmp_dir = tmp_dir\n",
    "        self.polya_dict = polya_dict\n",
    "        self.mis_intron_length = mis_intron_length\n",
    "        self.corExcept_dis = corExcept_dis\n",
    "\n",
    "    def job_compute(self):\n",
    "        p = Pool(processes=self.thread)\n",
    "        result = []\n",
    "        for branch in self.processed_read:\n",
    "            chrom, strand = branch\n",
    "            chrand_processed_read = self.processed_read[branch]\n",
    "            chrand_ref_exon = self.ref_exon[branch]\n",
    "            chrand_ref_junction = self.ref_junction[branch]\n",
    "            chrand_ref_single_exon_trans = self.ref_single_exon_trans[branch]\n",
    "            chrand_ref_mutple_exon_trans = self.ref_mutple_exon_trans[branch]\n",
    "            chrand_left_sj_set = self.left_sj_set[branch]\n",
    "            chrand_right_sj_set = self.right_sj_set[branch]\n",
    "            chrand_junction_dict = self.junction_dict[branch]\n",
    "            result.append(p.apply_async(coco_operation, (chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans,\n",
    "                          chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, self.sj_correction_window, self.mis_intron_length, self.corExcept_dis, self.polya_dict,)))\n",
    "\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def result_collection(self):\n",
    "        collected_single_exon_read = Vividict()\n",
    "        collected_multi_exon_read = Vividict()\n",
    "        collected_rss = []\n",
    "        collected_res = []\n",
    "        path_to_log = f'{self.tmp_dir}/read_correction.log'\n",
    "        path_to_corrected_bed = f'{self.tmp_dir}/Corrected_reads.bed'\n",
    "\n",
    "        result = self.job_compute()\n",
    "        with open(path_to_log, 'w') as flog, open(path_to_corrected_bed, 'w') as fbed:\n",
    "            for res in result:\n",
    "                chrom, strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst = res.get()\n",
    "                collected_single_exon_read[(chrom, strand)] = single_exon_read\n",
    "                collected_multi_exon_read[(chrom, strand)] = multi_exon_read\n",
    "                collected_rss.extend(rss_dis_lst)\n",
    "                collected_res.extend(res_dis_lst)\n",
    "                for read_id, tag_dict in correction_log.items():\n",
    "                    read_name = read_id.split('_', 1)[1]\n",
    "                    attributes = '\\t'.join('{}: {}'.format(\n",
    "                        key, value) for key, value in tag_dict.items())\n",
    "                    flog.write(f'{read_name}\\t{attributes}\\n')\n",
    "\n",
    "                for read_id, full_block in corrected_read.items():\n",
    "                    read_name = read_id.split('_', 1)[1]\n",
    "                    bed_block = splicing_to_bed_block(\n",
    "                        chrom, strand, read_name, full_block)\n",
    "                    fbed.write(f'{bed_block}\\n')\n",
    "        return collected_single_exon_read, collected_multi_exon_read, collected_rss, collected_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrand_read_list1 = {}\n",
    "# chrand_read_list1['adcc854a-2c55-432c-9d65-11ca1d8c9eb4'] = chrand_read_list['adcc854a-2c55-432c-9d65-11ca1d8c9eb4']\n",
    "# # chrand_read_list1['adcc854a-2c55-432c-9d65-11ca1d8c9eb4'] = [167500,167519, 167584, 167610]\n",
    "\n",
    "\n",
    "# for (chrom, strand) in processed_read:\n",
    "# \tchrand_read_list = processed_read[(chrom, strand)]\n",
    "# \tchrand_ref_exon = ref_exon[(chrom, strand)]\n",
    "# \tchrand_ref_junction = ref_junction[(chrom, strand)]\n",
    "# \tchrand_ref_single_exon_trans = ref_single_exon_trans[(chrom, strand)]\n",
    "# \tchrand_ref_mutple_exon_trans = ref_mutple_exon_trans[(chrom,strand)]\n",
    "# \tchrand_left_sj_set = left_sj_set[(chrom,strand)]\n",
    "# \tchrand_right_sj_set = right_sj_set[(chrom,strand)]\n",
    "# \tchrand_junction_dict = junction_dict[(chrom,strand)]\n",
    "# \tsj_correction_window = 40\n",
    "# \tmis_intron_length = 150\n",
    "# \tcorExcept_dis=4\n",
    "# \tpolya_dict=None\n",
    "# \tsingle_exon_read = {}\n",
    "# \ttmp_dir='./'\n",
    "# \t# with open ('test.out', 'w') as fw:\n",
    "# \t# \tfor read, splicing in tqdm(chrand_read_list.items(), desc = f'{strftime(\"%Y-%m-%d %H:%M:%S\")}: Collapsing raw reads from {chrom} {strand}'):\n",
    "# \t# \t\tif len(splicing) == 2:\n",
    "# \t# \t\t\tsingle_exon_read_collapse(splicing, chrand_ref_exon, 40, single_exon_ead)\n",
    "# \t# \t\tif len(splicing) > 2:\n",
    "\n",
    "# \tsingle_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst = coco_operation(chrom, strand, chrand_read_list, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_single_exon_read, collected_multi_exon_read = CoCoWrapper(32, processed_read, ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans,\n",
    "                                                                    left_sj_set, right_sj_set, junction_dict, tmp_dir='.', sj_correction_window=40, mis_intron_length=150, corExcept_dis=4, polya_dict=None).result_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
